Refining and enhancing below text, ensuring language is polished, clear, and professional.
[Text]“The impassioned orator, bard, or musician …with his varied tones and cadences … excites the strongest emotions in his hearers.” Charles Darwin, 1871 
Everyday communication involves the expression and reception of numerous verbal and nonverbal cues. In spoken exchanges, at least two types of information can be conveyed (Crystal, 1969; Laver, 1994). One type is linguistic information used for a transactional purpose, essentially the “message-oriented” (Brown & Yule, 1983, p. 2) semantic content of the words and phrases used to express beliefs and ideas (i.e., what is said). A second is social-emotional information used for an interactional or paralinguistic purpose (i.e., how speech is said). The listener is provided with speaker- and situation- specific cues which serve to “…establish and maintain social relationships” (Brown & Yule, p. 3), and which can modify the social significance of the meaning of an utterance. 
One of the most common means of transmitting interactional information in everyday communication is through prosody. The ancient Greeks used the word “προσῳs23δία(prosodia) to “refer to features of speech which were not indicated in orthography, specifically to the tone or melodic accent which characterized full words …” (Couper-Kuhlen, 1986, pp. 1). The neurologist Monrad-Krohn (1947a) described prosody as “of great importance in conveying the meaning of the speaker” (pp. 405) and as “that faculty of speech which conveys different shades of meaning by means of variations in stress and pitch” (Monrad-Krohn, 1947b, pp. 255). Prosody is typically conveyed through variations in voice fundamental frequency (referred to throughout this document as F0), intensity, speech rate, and duration (e.g., Cruttenden, 1997; Cutler, Dahan, & Van Donselaar, 1997; Frick, 1985; Monnot, Lovallo, Nixon, & Ross, 2002; Pell, 2001; Schirmer & Kotz, 2006). These physical attributes are perceived along the psychological dimensions of pitch, loudness, and time (Frick, 1985; Johns-Lewis, 1986), and they provide the melody and rhythm of speech (Ethofer, Van De Ville, Scherer, & Vuilleumier, 2009; Grossman, Bemis, Skwerer, & Tager-Flusberg, 2010; Orbelo, Testa, & Ross, 2003). The programme of research presented in this thesis involved recording and measuring the acoustical properties and the semantic emotional properties of a novel set of stimuli. These stimuli were then used in studies conducted for the purposes of 1) examining the ability of younger and older listeners to recognize the emotions expressed in speech and 2) investigating the influence of the portrayal of emotion in speech on the intelligibility of speech in noise for both younger and older listeners. In the current chapter, background literature relevant to each of these goals is reviewed. 
Functions of prosody. Prosody can provide cues to information at a variety of different levels of communication, including grammatical, indexical, pragmatic, and affective. At the grammatical level, prosody can influence the interpretation of morphological or syntactic structures in various ways, such as the use of lexical stress by a talker to disambiguate words (e.g., a warm canine is a hot dog vs. a sausage in a bun which is a hotdog; Cutler et al, 1997; Grossman et al., 2010) or phrases (e.g., “She asked him to call Dave.” vs. “She asked him to call, Dave.”), or to differentiate between declarative and interrogative sentences (e.g., Heilman & Bowers, 1990). Prosody can also serve an indexical function by providing information about the identity of an individual speaker. Indexical prosodic features, such as idiosyncratic voice quality characteristics, can inform the listener regarding a speaker’s age, gender, social class and ethnicity (Peppé, 2009; Paulmann, Pell, & Kotz, 2008; Scherer & Giles, 1979). Prosody can also serve a pragmatic function, helping to emphasize information within an utterance (e.g., “We met at nine”/“We met at eight”/“I was on time”/“No, you were late”; Lerner & Loewe, 1958), or marking the difference between new and old information (Villaume, Brown, & Darling, 1994). In addition to these functions, prosody can provide discourse cues that are important in conversation (Villaume et al., 1994). For example, prosody can signal turn-taking through a lowering of pitch and a decrease in amplitude at the end of an utterance (Cutler & Pearson, 1986), making it less likely for a talker to be cut off by his or her conversational partner. 
The focus of this dissertation is affective prosody, cues in speech which can be used to express a talker’s emotional state (Peppé, 2009; Shea et al., 2007; Villaume et al., 1994). Viewed from an evolutionary perspective, the use of prosody to express emotion plays an important role in everyday social interactions (Juslin & Scherer, 2005; Schirmer, Striano, & Friederici, 2005). Indeed, emotion was identified by Jakobson and Halle (1971) as one of the main functions of communication. The expression and understanding of emotion plays a central role in vocal communication and social interaction (Banse & Scherer, 1996; Pittam & Scherer, 1993; Scherer, 2003). The processing of emotional information is so crucial to the maintenance of healthy interpersonal relationships and difficulties in interpreting affective prosody in otherwise healthy people during everyday conversations have been linked to negative well-being, increased feelings of depression (Carton, Kessler, & Pape, 1999) and difficulties in social interactions (Poole, Tobias, & Vinogradov, 2000). 
Acoustical Cues to Emotion in Speech 
Numerous researchers have examined the acoustical parameters which are modified when different emotions are expressed according to what a talker is feeling or portraying (De Abreu, Mathon, & Mosca, 2009). Researchers have suggested that the most prominent, but not the only, acoustical parameters of speech when it is produced to express different emotions are related to the F0, namely its mean, minimum, maximum, and range (e.g., Bänziger & Scherer, 2005; Breitenstein, Van Lancker, Daum, & Waters, 2001; Busson, Bulut, Lee, & Narayanan, 2009; Ross et al., 2001). Banse and Scherer (1996) and Frick (1985) have suggested that F0 and temporal parameters have the strongest influence on differentiating between different emotions. Utterance duration has been identified as an important parameter for cueing specific emotions (Vroomen, Collier, & Mozziconacci, 1993). Indeed, when the F0 and duration parameters of specific emotions were copied onto monotonous speech, recognition rates for the emotions were copied onto monotonous speech, recognition rates for the emotions were as high as 81%, suggesting that these cues are extremely important for cueing the particular emotions (Vroomen et al., 1993).
Acoustical parameter profiles of specific emotions.
 Four of the emotions which will be used to record the stimuli used in this thesis, specifically angry, fearful, happy, and sad, have been used in numerous previous investigations into the production and perception of emotional speech. As such, the acoustical parameters specific to portrayals of these emotions have been well-documented. It should be noted that the research on portrayals of surprise, disgust, and neutral emotions is more limited. While there has been some variability in the acoustical parameters measured by previous researchers, most of the investigations have focused on voice F0 and temporal parameters, as these are thought to have the strongest effects on listeners’ accuracy in differentiating between emotions (Banse & Scherer, 1996; Breitenstein, Van Lancker, & Daum, 2001; Russell, Bachorowski, & Fernández-Dols, 2003). Indeed, in seminal papers in this area (e.g., Johnstone & Scherer, 2000; Murray & Arnott, 1993; Pittam & Scherer, 1993; Scherer, 2003), emotions are commonly described based on mean and range of F0, mean and range of intensity and mean duration. It is important to note that the acoustical parameters of emotions have been described by a number of researchers in comparison to a neutral voice (Mozziconacci, 2002; Murray & Arnott, 1993). In the next section a description of findings will be provided for each of the emotions portrayed to create the set of stimuli, namely anger, disgust, fear, happiness, surprise, sadness, and neutral (see Chapter 3). 
Few researchers have examined the acoustical parameters of neutral speech. Barrett & Paus (2002) found that neutral stimuli had higher F0 values than sad stimuli. Portrayals of sad affective prosody are characterized by decreases in mean F0, F0 range, and mean intensity. Portrayals of anger, fear, and happiness have been shown to be quite similar to each other. Anger is typically portrayed through increases in mean F0, F0 variability, and F0 range, as well as increases in mean intensity, and mean duration. Similarly, fear is portrayed through increases in mean F0 and intensity and reduced duration. Mean F0 range during portrayals of fearful affective prosody has been shown to both increase (e.g., Johnstone & Scherer, 2000) and decrease (e.g., Banse & Scherer, 1996). Breitenstein et al. (2001) posit that mean F0 and speech rate are highest for emotions associated with high sympathetic arousal, for example, anger and fear. Happy is one of the few positive emotions to have been studied (Banse & Scherer, 1996), and it is portrayed through increases in mean F0, F0 range, and F0 variability. Research on portrayals of disgust is inconsistent, which may help to explain why recognition accuracy for this emotion is typically so low (Johnstone & Scherer, 2000). In comparison to angry affective prosody, stimuli spoken with a disgusted voice have lower intensity and mean F0 (Hammerschmidt & Jürgens, 2007). Compared to neutral, disgust is portrayed through a low mean F0, low intensity, and a slower speech rate (Schuller, Rigoll, & Lang, 2004). Work by Trainor and colleagues (2000) has shown that stimuli portraying surprise have higher F0, larger F0 ranges, and longer durations compared to fearful stimuli. Stimuli spoken in a surprised voice are typically produced with a fast speech rate (Schuller et al., 2004). These patterns of acoustical parameters found for different emotions will be important when the acoustical parameters of the set of stimuli created in Chapter 3 are discussed in Chapter 5. 
Studying Emotion Understanding 
Given the importance of emotions in everyday communication and social interaction, it is not surprising that there is a long history of research into how emotions are understood1. Most of this research has been conducted in the visual domain, using text and photos (Stevenson & James, 2008). Indeed, few researchers have focused on emotion as it pertains to how we perceive or produce speech (Juslin & Scherer, 2005; Ladd, Scherer, & Silverman, 1986) or how we comprehend spoken language. Affective prosody has long held an overlooked or “Cinderella” role in acoustic research (Bachorowski & Owren, 1995; Peppé, 2009) and it was not until the early 1980s that researchers such as Scherer and his colleagues began to systematically examine the production and processing of affective prosody (e.g., Scherer, 1982, 1986). It has been suggested that this lag in the development of research on how emotions are coded in the auditory modality relative to the extensive work in the visual modality is due to the difficulty in obtaining authentic recordings of emotional vocal expressions (Scherer, Banse, Wallbott, & Goldbeck, 1991). In the following section the particular types of stimuli used to study the processing of emotion in both the visual and auditory modalities will be described.