benchmark_name: serving_perf_eval
# Inference server config 
backend: MAAS
url: http://if-dad3oadbk3d5h3fb-service:80/v1/chat/completions
model: qwen1.5-14b-chat-fp8
tokenizer: /mnt/public/Qwen_Qwen1.5-14B-Chat-FP8

# Dataset config
dataset_name: local
dataset_path: /mnt/chenyonghua/long_bench-qwen2-8k_32k.json
num_prompts: 1000

# Generation config
temperature: 0.0

# Perf test config
perf_test_type: MULTIPLE
concurrency_list:
  - 1
  - 2
  - 4
request_rate_list: 
  - -1
save_data: True